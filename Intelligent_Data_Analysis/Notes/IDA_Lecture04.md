# Intelligent Data Analysis

---

## Lecture 4. Vector Representation of Documents



### 1. Vector Notation for Documents

1. Suppose that we have a set of documents $D$ = {$\mathbf {d_1, d_2, ..., d_N}$} 
   - As the **corpus** for IR

2. Suppose that the number of different words in the **whole corpus** is $\mathbf V$
   - As the **vocabulary size**

3. Suppose a document $d$ in $D$ contains $\mathbf M$ **different terms**: {$\mathbf {t_{i(1)}, t_{i(2)}, ..., t_{i(M)}}$}
4. Finally, suppose term $\mathbf t_{i(m)}$ occurs $f_{i(m)}$ times



### 2. Uniqueness

1. Is the mapping between documents and vectors *one-to-one*?
2. If $\lambda$ is a scalar and $vec(d_1) = \lambda vec(d_2)$, what does this tell you about $d_1$ and $d_2$?



### 3. Example



### 4. Document Length



### 5. Document Similarity



### 6. Cosine Similarity

