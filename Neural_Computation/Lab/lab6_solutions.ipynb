{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-Uf0pguMU1J"
   },
   "source": [
    "# Neural Computation (Autumn 2019)\n",
    "# Lab 6: Automatic Differentiation (Autograd)\n",
    "\n",
    "Last week, we gave you a very brief introduction to Pytorch. This week, we will dive more deeply into the Deep Learning framework. By the end of this tutorial, you will know:\n",
    "\n",
    "- How to create tensors in Pytorch via `torch.Tensor`\n",
    "- How backpropgation is performed in Pytorch (with `autograd`)\n",
    "- How to split the dataset into training and validation sets\n",
    "- How to build a model using `nn.Module` and `nn.Linear` and train that model\n",
    "- How to evaluate the trained model using the validation set\n",
    "\n",
    "## Pytorch Tensors\n",
    "\n",
    "The most basic building block of any Deep Learning library is tensors, which are matrix-like data structures very similar to Numpy's ndarrays with the advantage being that Tensors can also be stored/used on a GPUs to accelerate computing. A scalar has zero dimension, so is called 0D tensor. A vector (i.e., 1D tensor) has one dimension, while a matrix (2D tensor) has two dimension. Note that we introduced tensors in Lab 3 (Advanced Numpy, Tensors & Tensor Operations). If you do not remember what a tensor is, please revisiting Lab 3 again.\n",
    "\n",
    "In this section, we will show you how to create a tensor using Pytorch. First, we need to `import` the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1nX9IT1vRxAk"
   },
   "source": [
    "You can construct a 3x4 randomly initialised matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7167, 0.6955, 0.7987],\n",
      "        [0.3798, 0.6162, 0.3936],\n",
      "        [0.0431, 0.0778, 0.8484],\n",
      "        [0.5857, 0.7959, 0.5468]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(4,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsm3IfN0W_qb"
   },
   "source": [
    "Construct a tensor directly from data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0000, 4.5000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([3, 4.5])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SWkStdiyXM1K"
   },
   "source": [
    "You can retrieve the size of the tensor using `size` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGIIR6MSXrpy"
   },
   "source": [
    "There are many operations that can be performed on tensors. The addition operation can be done as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0353, 1.2869, 0.5589, 0.8425],\n",
      "        [0.6672, 0.9641, 1.8257, 0.7076],\n",
      "        [0.7757, 0.5222, 0.3830, 1.8068]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "y = torch.rand(3,4)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MksZH3NjYAvo"
   },
   "source": [
    "Or you can use another syntax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0353, 1.2869, 0.5589, 0.8425],\n",
      "        [0.6672, 0.9641, 1.8257, 0.7076],\n",
      "        [0.7757, 0.5222, 0.3830, 1.8068]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bq9lIO8TYOCA"
   },
   "source": [
    "You can also provide an output tensor as argument as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0353, 1.2869, 0.5589, 0.8425],\n",
      "        [0.6672, 0.9641, 1.8257, 0.7076],\n",
      "        [0.7757, 0.5222, 0.3830, 1.8068]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(3,4)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M6Av5bfUYlYq"
   },
   "source": [
    "You can also convert a Torch Tensor to a Numpy Array using `numpy()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "torch.float32\n",
      "[1. 1. 1. 1. 1.]\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5)\n",
    "print(x)\n",
    "print(x.dtype)\n",
    "\n",
    "y = x.numpy()\n",
    "print(y)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kTTRw5aeZU_8"
   },
   "source": [
    "Convert Numpy Array to Torch Tensor. Notice how changing the np array has changed the Torch Tensor automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2.]\n",
      "tensor([2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = np.ones(3)\n",
    "y = torch.from_numpy(x)\n",
    "\n",
    "np.add(x, 1, out=x)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gx2EYILCZ69-"
   },
   "source": [
    "Tensors can be moved onto any device using the `.to` method. You can check whether a GPU is available using the `torch.cuda.is_available()` method. The `.to()` method sends your tensor to whatever device you specify, including your GPU (referred to as `cpu`) or your GPUs (referred to as `cuda` or `cuda:0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.8271, 1.2441, 1.2916, 1.4670],\n",
      "        [1.3684, 1.8541, 1.4771, 1.3148],\n",
      "        [1.0563, 1.8261, 1.2163, 1.6201]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'  # check whether a GPU is available\n",
    "y = torch.ones(3,4, device=device)  # directly create a tensor on GPU\n",
    "x = torch.rand(3,4).to(device)      # or just use .to(device) \n",
    "z = x+y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iRU_ta07bcll"
   },
   "source": [
    "As you have seen, `torch.Tensor` is the central class of the Pytorch package. If you now set its attribute `.require_grad` as `True`, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
    "\n",
    "The following piece of codes creates a tensor and set `requires_grad=True` to track computation with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ucWrE-uOcweu"
   },
   "source": [
    "Perform a tensor operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kMxdIiPDc-OR"
   },
   "source": [
    "A `Function` is also an important class for autograd implementation in Pytorch. ``Tensor`` and ``Function`` are interconnected and build up an acyclic\n",
    "graph, that encodes a complete history of computation. Each tensor has\n",
    "a ``.grad_fn`` attribute that references a ``Function`` that has created\n",
    "the ``Tensor`` (except for Tensors created by the user - their\n",
    "`grad_fn is None`). In the example above, you see that `y` has a `grad_fn` since it was created as a result of an operation. We can print the value of that attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002B1381EDEC8>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5QyluhmyeCpB"
   },
   "source": [
    "You can do more operations on `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[18., 18.],\n",
      "        [18., 18.]], grad_fn=<MulBackward0>)\n",
      "tensor(18., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 2\n",
    "out = z.mean()\n",
    "\n",
    "print(z)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-9vAUHUeaPr"
   },
   "source": [
    "You can change an existing Tensor's `requires_grad` flag in-place by using `.requires_grad_(...)`. The input flag defaults to `False` if not given. Note that anu operation that mutates a tensor in-place is post-fixed with an `_`. For example, `x.copy_(y)` and `x.t_()` will change `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2)\n",
    "print(x.requires_grad)  # default to False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)   # change the flag to True\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<SumBackward0 object at 0x000002B1382039C8>\n"
     ]
    }
   ],
   "source": [
    "y = (x + 1).sum()\n",
    "print(y.requires_grad)\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zptrR5EcgJhK"
   },
   "source": [
    "## Gradients\n",
    "\n",
    "Let's backprop now. Consider the fowllowing piece of codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y * y * 3\n",
    "out= z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:  tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "2:  tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "3:  <AddBackward0 object at 0x000002B138204088>\n",
      "4:  tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>)\n",
      "5:  tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"1: \", x)\n",
    "print(\"2: \", y)\n",
    "print(\"3: \", y.grad_fn)\n",
    "print(\"4: \", z)\n",
    "print(\"5: \", out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QlVpst3Pg_9N"
   },
   "source": [
    "If you want to compute the derivatives, you can call ``.backward()`` on\n",
    "a ``Tensor``. If ``Tensor`` is a scalar (i.e. it holds a one element\n",
    "data), you don’t need to specify any arguments to ``backward()``,\n",
    "however if it has more elements, you need to specify a ``gradient``\n",
    "argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ibru7AK9hNtj"
   },
   "source": [
    "Since `out` contains a single scalar (i.e., mean), `out.backward()` is equivalent to `out.backward(torch.tensor(1.))`.  You can retrieve the gradient of d(out)/dx as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dvVToP20Oq9D"
   },
   "source": [
    "You should have got a matrix of ``4.5``. Let’s call the ``out``\n",
    "*Tensor* “$o$”.\n",
    "We have that $o = \\frac{1}{4}\\sum_i z_i$,\n",
    "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$.\n",
    "Therefore,\n",
    "$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$, hence\n",
    "$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGDNbmVhihEh"
   },
   "source": [
    "Mathematically, if you have a vector valued function $\\vec{y}=f(\\vec{x})$,\n",
    "then the gradient of $\\vec{y}$ with respect to $\\vec{x}$\n",
    "is a Jacobian matrix:\n",
    "\n",
    "\\begin{align}J=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "Generally speaking, ``torch.autograd`` is an engine for computing\n",
    "vector-Jacobian product. That is, given any vector\n",
    "$v=\\left(\\begin{array}{cccc} v_{1} & v_{2} & \\cdots & v_{m}\\end{array}\\right)^{T}$,\n",
    "compute the product $v^{T}\\cdot J$. If $v$ happens to be\n",
    "the gradient of a scalar function $l=g\\left(\\vec{y}\\right)$,\n",
    "that is,\n",
    "$v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$,\n",
    "then by the chain rule, the vector-Jacobian product would be the\n",
    "gradient of $l$ with respect to $\\vec{x}$:\n",
    "\n",
    "\\begin{align}J^{T}\\cdot v=\\left(\\begin{array}{ccc}\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
    "   \\vdots & \\ddots & \\vdots\\\\\n",
    "   \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial y_{m}}\n",
    "   \\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "   \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
    "   \\vdots\\\\\n",
    "   \\frac{\\partial l}{\\partial x_{n}}\n",
    "   \\end{array}\\right)\\end{align}\n",
    "\n",
    "(Note that $v^{T}\\cdot J$ gives a row vector which can be\n",
    "treated as a column vector by taking $J^{T}\\cdot v$.)\n",
    "\n",
    "This characteristic of vector-Jacobian product makes it very\n",
    "convenient to feed external gradients into a model that has\n",
    "non-scalar output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qhiFcpowpNhC"
   },
   "source": [
    "## How to define a model in Pytorch?\n",
    "\n",
    "### An example \n",
    "\n",
    "To illustrate this step, let's create some synthetic data. We choose a vector of some points for our feature `x` and create our labels (targets) using the following model $y=a + b \\cdot x + \\epsilon\\cdot  \\mathcal{N}$, where `a`, `b` and $\\epsilon$ are some constants and $\\mathcal{N}$ is noise following a standard normal distribution (mean=0, variance=1).\n",
    "\n",
    "#### **Question 1**:\n",
    "Let's consider `a=1`, `b=2` and $\\epsilon=0.1$. Could you please generate a vector of 100 points for our feature `x` and another vector of the same size for our target `y`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add you codes here (use x and y as variable names for input and tagets)\n",
    "np.random.seed(42)\n",
    "x = np.random.rand(100, 1)\n",
    "y = 1 + 2 * x + 0.1 * np.random.randn(100, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oycbp5Aksb4Z"
   },
   "source": [
    "Now we split the dataset into a trainning set (used for training, about 80% of the original dataset) and a validation set (used for testing, about 20%). We need to shuffle the array of indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before shuffle: \n",
      " [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95\n",
      " 96 97 98 99]\n",
      "After shuffle: \n",
      " [76 83 80 98  2 77 71 84 89 50 40 51 67 86 37 49  4 10 69 81  9 54 55 87\n",
      " 64 44 90 75 33 30 93 95 14 61 11 13 15  7  0 19 35  6 12 65 70 88 56 58\n",
      " 28 38 91 42  8 73 39 85 25 92 41 26  1 22 21 46 74 79 78 72 57 53 24 17\n",
      " 66 32 31 62 59 52 82 23 36  5 45 99 43 16 48 94 34  3 18 47 60 68 63 27\n",
      " 96 29 20 97]\n"
     ]
    }
   ],
   "source": [
    "indx = np.arange(100)  # indices for all data points in x\n",
    "print(\"Before shuffle: \\n\", indx)\n",
    "\n",
    "np.random.shuffle(indx)\n",
    "print(\"After shuffle: \\n\", indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xEEWsPn05kb"
   },
   "source": [
    "Now split the indices into two sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indx = indx[:80]  # first 80% for training\n",
    "val_indx = indx[80:]    # remaining 20% for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-Sb75Sx1Jpm"
   },
   "source": [
    "Split the dataset into training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80\n",
      "20 20\n"
     ]
    }
   ],
   "source": [
    "# Generate inputs and targets for training step\n",
    "x_train, y_train = x[train_indx], y[train_indx]\n",
    "print(x_train.size, y_train.size)\n",
    "\n",
    "# Generate inputs and targets for validation step\n",
    "x_val, y_val = x[val_indx], y[val_indx]\n",
    "print(x_val.size, y_val.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etPmmYt3-F56"
   },
   "source": [
    "We need to convert these Numpy's ndarray into Torch tensors of type `float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.from_numpy(x_train).float()\n",
    "y_train_tensor = torch.from_numpy(y_train).float()\n",
    "\n",
    "x_val_tensor = torch.from_numpy(x_val).float()\n",
    "y_val_tensor = torch.from_numpy(y_val).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_YyKFUrH1UMT"
   },
   "source": [
    "We can also plot the points using the `scatter` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2b161f98d48>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(nrows = 1, ncols = 2)\n",
    "axs[0].scatter(x_train, y_train)  # plot the training dataset\n",
    "axs[1].scatter(x_val, y_val)      # plot the validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_i3x6addpIP7"
   },
   "source": [
    "### A simple linear gression model\n",
    "\n",
    "Let's difine a simple linear regression model to learn the values for two parameters `a` and `b` in the model above.\n",
    "\n",
    "As you might see last week, a model can be constructed in Pytorch using the `torch.nn` class. To explicitly define the model, you need to implement (at least) the following methods:\n",
    "\n",
    "- `__init__(self)`, which defines the components that make up the model. Here, you are not limited to defining parameters and other models (or layers in neural networks) as our model's attributes (see more about this later).\n",
    "- `forward(self, x)`, which performs the actual computation, that is, it ouputs a prediction, given the input `x`. You need not call the `forward(x)` method, and should call the whole model itself to perform a forward pass and output predictions.\n",
    "\n",
    "Out first model will look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class FirstModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = nn.Parameter(torch.randn(1).float())\n",
    "        self.b = nn.Parameter(torch.randn(1).float())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.a + self.b * x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGQPchZ6z_kT"
   },
   "source": [
    "In the `__init__` method, we define two parameters, `a` and `b`, using the `Parameter()` class. By doing this, you can invoke the `parameters()` method of our model to retrieve an iterator over all model's parameters, that we can feed our optimiser. Moreover, we can get the current values for all parameters using the model's `state_dict()` method.\n",
    "\n",
    "In the following, we will use stochastic gradient descent, i.e., the `SGD` method from `torch.optim` package, which takes two arguments: the list of model's parameters (`model.parameters()`) and the learning rate `lr`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: \n",
      " OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Now we can create a model\n",
    "model = FirstModel().to(device)\n",
    "\n",
    "# we can also inspect its parameters\n",
    "print(\"Before training: \\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After training: \n",
      " OrderedDict([('a', tensor([1.1552], device='cuda:0')), ('b', tensor([1.7113], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "# set learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# set number of epoches, i.e., number of times we iterate through the training set\n",
    "epoches = 100\n",
    "\n",
    "# We use mean square error (MSELoss)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# We also use stochastic gradient descent (SGD) to update a and b\n",
    "optimiser = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    model.train()             # set the model to training mode \n",
    "    optimiser.zero_grad()     # avoid accumulating gradients\n",
    "    y_pred = model(x_train_tensor.to(device))\n",
    "    loss = loss_fn(y_train_tensor.to(device), y_pred)\n",
    "    loss.backward()           # calculate gradients\n",
    "    optimiser.step()          # update model's params\n",
    "\n",
    "print(\"After training: \\n\", model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yL2y-zlk_P8v"
   },
   "source": [
    "When setting the number of epoches sufficiently large, you should be able to obtain some values for parameters `a` and `b` which are really close to their ground-truth values of 1 and 2. You can play with the model above by changing the number of epoches (`epoches`) and the learning rate (`lr`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EdPqZj1qATwP"
   },
   "source": [
    "### Nested model\n",
    "\n",
    "In our model above, we manually created two parameters to perform a linear regression. We can also use Pytorch's `Linear` model as an attribute to our model, which results in a nested model. \n",
    "\n",
    "To do this, we need to change the `__int__` method, where we create an attribute that contains our nested `Linear` model. Also in the `forward()`, we will simply call the nested model itddelf to perform the forward pass.\n",
    "\n",
    "Our new model will look like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # a simple linear layer with an input and an output\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MXR9UKr0B8OL"
   },
   "source": [
    "We can now call inspect the model's parameters by calling `parameters()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.2191]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([0.2018], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "new_model = NewModel().to(device)\n",
    "print(list(new_model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H650FfseCjhj"
   },
   "source": [
    "You should see that the model has two parameters. The first one is the **weight** `b`, while the other one is the **bias** `a` in our linear model defined at the beginning (recall that $y=a + bx + \\epsilon \\cdot \\mathcal{N}$). You can see this clearly when using the `state_dict()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[-0.2191]], device='cuda:0')), ('linear.bias', tensor([0.2018], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(new_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewModel(\n",
      "  (linear): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print the model\n",
    "print(new_model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hQJK86xVLfSV"
   },
   "source": [
    "Because we use SGD as our optimiser, so we need mini-batches (i.e., small subsets of our dataset) to feed the model. In Pytorch, we can use the `DataLoader` class to do this. We simply need to tell it which dataset (of `TensorDataset`) to use, the size of the mini-batch (or simply batch size). The loader is an iterator-like, which can loop over the dataset and fetch a adifferent mini-batch every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKehfvlILlZQ"
   },
   "source": [
    "Let's see how we train the model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: \n",
      " OrderedDict([('linear.weight', tensor([[-0.4869]])), ('linear.bias', tensor([0.5873]))])\n"
     ]
    }
   ],
   "source": [
    "# Now we can create a model\n",
    "new_model = NewModel()\n",
    "\n",
    "# we can also inspect its parameters\n",
    "print(\"Before training: \\n\", new_model.state_dict())\n",
    "\n",
    "# set learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# set number of epoches, i.e., number of times we iterate through the training set\n",
    "epoches = 100\n",
    "\n",
    "# We use mean square error (MSELoss)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# We also use stochastic gradient descent (SGD) to update a and b\n",
    "optimiser = optim.SGD(new_model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-ec28257bc9a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nc\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-954043b455f4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Miniconda3\\envs\\nc\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nc\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\envs\\nc\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #1 'self' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "    new_model.train() \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # send tensors to device (cpu/cuda)\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        optimiser.zero_grad()\n",
    "        y_pred = new_model(x_batch)\n",
    "        loss = loss_fn(y_batch, y_pred)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "print(\"After training: \\n\", new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v2filI6iDWwk"
   },
   "source": [
    "So far, we have defined an optimiser, a loss function and a (nested) model. We realise that if we use the codes above, we have to modify it whenever we'd like to use a different optimiser or a different loss function. You might think of making our codes more generic. How about writing a function that takes three arguments (optimiser, loss function and a model) and perform the training step. You will see below how to write a function in Python which returns another function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_code(model, loss_fn, optimiser):\n",
    "\n",
    "    # define a function inside another function\n",
    "    def train_step(x_batch, y_batch):\n",
    "        optimiser.zero_grad()\n",
    "        y_pred = model(x_batch)   # forward pass\n",
    "        loss = loss_fn(y_batch, y_pred)  # calculate loss value\n",
    "        loss.backward()                # autograd\n",
    "        optimiser.step()               # update parameters  \n",
    "        return loss.item()             # return the loss\n",
    "\n",
    "    # return the newly defined function\n",
    "    return train_step                # return a function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1tW68QyFNNm"
   },
   "source": [
    "You can now perform the training process as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NewModel()\n",
    "print(new_model.state_dict())\n",
    "\n",
    "# set learning rate\n",
    "lr = 1e-1\n",
    "\n",
    "# set number of epoches, i.e., number of times we iterate through the training set\n",
    "epoches = 100\n",
    "\n",
    "# We use mean square error (MSELoss)\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "# We also use stochastic gradient descent (SGD) to update a and b\n",
    "optimiser = optim.SGD(new_model.parameters(), lr=lr)\n",
    "# after this step, train_step is actually a FUNCTION, which takes x_train_tensor \n",
    "# y_train_tensor as inputs and return the loss value\n",
    "train_step = generic_code(new_model, loss_fn, optimiser)\n",
    "\n",
    "# list to record the loss over training course\n",
    "losses = list()\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        losses.append(train_step(x_batch, y_batch))\n",
    "\n",
    "print(new_model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vlTQRxXTczN"
   },
   "source": [
    "You can now plot the loss value over time as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(losses)), losses, label=\"Training loss\")\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8VPPsolIfak"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We have not used the validation set that we created at the beginning of the tutorial. We have split the dataset of 100 points into a training set (80%) and a validation set (20%). We now change our model to include the evaluation phase, that is, computing the validation loss. Intuitively speaking, since we do not use the validation set when training the model, so the validation set is actually *unseen* to our model, and turns out to be a good choice to inspect how well our model performs on unseen data (i.e., making predictions). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V284foTANIn9"
   },
   "source": [
    "We first need to create a DataLoader for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = TensorDataset(x_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cgj7wSc5Nx10"
   },
   "source": [
    "Our training loop should look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NewModel().to(device)\n",
    "print(new_model.state_dict())\n",
    "\n",
    "lr = 1e-1\n",
    "epoches = 20\n",
    "loss_fn = nn.MSELoss()\n",
    "optimiser = optim.SGD(new_model.parameters(), lr=lr)\n",
    "\n",
    "losses = list()\n",
    "val_losses = list()\n",
    "train_step = generic_code(new_model, loss_fn, optimiser)\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    new_model.train()\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        losses.append(train_step(x_batch, y_batch))\n",
    "        \n",
    "        with torch.no_grad():       # fix the model's params\n",
    "            for x_val, y_val in val_loader:\n",
    "                new_model.eval()    # set model to evaluation mode\n",
    "                y_pred = new_model(x_val)\n",
    "                val_loss = loss_fn(y_val, y_pred)\n",
    "                val_losses.append(val_loss.item())\n",
    "\n",
    "print(new_model.state_dict())\n",
    "plt.plot(range(len(losses)), losses,'r', label=\"Training loss\")\n",
    "plt.plot(range(len(val_losses)), val_losses,'g', label=\"Validation loss\")\n",
    "plt.xlabel(\"Training iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YSpK-2L4tKh"
   },
   "source": [
    "Given the learning rate in `np.linspace(0.01, 0.5, 50)`. Could you plot a graph showing how the validation loss changes according to different values of the learning rate? Please use a number of epoches of at most, e.g., 200 for reasonable runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NewModel().to(device)\n",
    "\n",
    "lrs = np.linspace(0.01, 0.5, 50)\n",
    "\n",
    "epoches = 200\n",
    "loss_fn = nn.MSELoss()\n",
    "optimiser = optim.SGD(new_model.parameters(), lr=lr)\n",
    "\n",
    "train_step = generic_code(new_model, loss_fn, optimiser)\n",
    "losses = list()\n",
    "\n",
    "for lr in lrs:\n",
    "    val_losses = list()\n",
    "    for epoch in range(epoches):\n",
    "      new_model.train()\n",
    "      for x_batch, y_batch in train_loader:\n",
    "          train_step(x_batch, y_batch)\n",
    "    with torch.no_grad():\n",
    "      for x_val, y_val in val_loader:\n",
    "        new_model.eval()\n",
    "        y_pred = new_model(x_val)\n",
    "        val_loss = loss_fn(y_val, y_pred)\n",
    "        val_losses.append(val_loss.item())\n",
    "        losses.append(np.mean(val_losses))\n",
    "plt.plot(lrs, losses,'b', label=\"Validation loss\")\n",
    "plt.xlabel(\"Learning Rates\")\n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W3yVOeYv4ryC"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snFj8Jcvz7Xh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab6_solutions.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
